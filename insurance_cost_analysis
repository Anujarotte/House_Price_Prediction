# ðŸ“Œ House Price Prediction with Regression Models

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline

# -------------------------------
# 1. Load and Inspect the Dataset
# -------------------------------
df = pd.read_csv("housing (1).csv")  # Replace with your file path

# Drop unnecessary columns
df.drop(['id', 'Unnamed: 0'], axis=1, inplace=True)

# Display dataset summary
print(df.describe())

# Count houses per floor category
floors_counts = df['floors'].value_counts().to_frame(name="count")
print(floors_counts)

# -------------------------------
# 2. Data Visualization
# -------------------------------

# Boxplot: House prices vs Waterfront view
sns.boxplot(x="waterfront", y="price", data=df)
plt.xlabel("Waterfront View (0=No, 1=Yes)")
plt.ylabel("Price")
plt.title("House Price Distribution by Waterfront View")
plt.show()

# Regression plot: sqft_above vs Price
sns.regplot(x="sqft_above", y="price", data=df)
plt.xlabel("Square Footage Above Ground (sqft)")
plt.ylabel("Price")
plt.title("Price vs. Square Footage Above Ground")
plt.show()

# -------------------------------
# 3. Simple Linear Regression
# -------------------------------
X = df[["sqft_living"]]
y = df["price"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lin_model = LinearRegression()
lin_model.fit(X_train, y_train)

print("Simple Linear Regression RÂ²:", lin_model.score(X_test, y_test))

# -------------------------------
# 4. Polynomial Regression (Pipeline)
# -------------------------------
features = ["floors","waterfront","lat","bedrooms","sqft_basement",
            "view","bathrooms","sqft_living15","sqft_above","grade","sqft_living"]

X = df[features]
y = df["price"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

poly_pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("poly", PolynomialFeatures(degree=2, include_bias=False)),
    ("model", LinearRegression())
])

poly_pipeline.fit(X_train, y_train)
print("Polynomial Regression RÂ²:", poly_pipeline.score(X_test, y_test))

# -------------------------------
# 5. Ridge Regression (Regularized Polynomial)
# -------------------------------
poly = PolynomialFeatures(degree=2, include_bias=False)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

ridge_model = Ridge(alpha=0.1)
ridge_model.fit(X_train_poly, y_train)

print("Ridge Regression RÂ²:", ridge_model.score(X_test_poly, y_test))
